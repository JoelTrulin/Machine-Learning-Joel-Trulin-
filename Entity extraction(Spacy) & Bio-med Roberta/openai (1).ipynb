{"cells":[{"cell_type":"markdown","metadata":{"id":"eMg6RM2CKp0U"},"source":["# setup"],"id":"eMg6RM2CKp0U"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2d4599f-f331-48fa-ab0c-b2ae485fa590","scrolled":true},"outputs":[],"source":["!pip install openai\n","!pip install kor\n","!pip install langchain"],"id":"e2d4599f-f331-48fa-ab0c-b2ae485fa590"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1f31380-87a1-4d6f-ab4d-66ff1c42a889"},"outputs":[],"source":["import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import openai\n","from langchain.chat_models import ChatOpenAI\n","from kor import create_extraction_chain, Object, Text\n","\n","\n","\n","# from dotenv import load_dotenv, find_dotenv\n","# _ = load_dotenv(find_dotenv()) # read local .env file\n","\n","openai.api_key = \"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\"\n","api_key = \"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\"\n","os.environ['OPENAI_API_KEY'] = api_key"],"id":"b1f31380-87a1-4d6f-ab4d-66ff1c42a889"},{"cell_type":"markdown","metadata":{"id":"gsU4rA-KZcDr"},"source":["# Dataset Preparation"],"id":"gsU4rA-KZcDr"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kovqt9BxZ-wB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694065795511,"user_tz":-330,"elapsed":25439,"user":{"displayName":"Joel Trulin J","userId":"11165460193007417230"}},"outputId":"85c21003-36a7-40cb-b278-23ce945b61cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"Kovqt9BxZ-wB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2V__KCz2ZhsL"},"outputs":[],"source":["import pandas as pd\n","# from IPython.display import display, HTML\n","# Read Dataset\n","data = pd.read_excel('/content/drive/MyDrive/Roche/04. ETNBC Utils - Sent to CapeStart.xlsx', usecols=[\n","                     'Title', 'Abstract', 'Exclusion Code']).dropna(axis=0, subset=['Title', 'Abstract']).fillna('Include')\n","data['Info'] = data['Title'].astype(str) + data['Abstract'].astype(str)\n","proc_data = data[['Info', 'Exclusion Code']].copy()"],"id":"2V__KCz2ZhsL"},{"cell_type":"markdown","metadata":{"id":"r4NZYpQXLAte"},"source":["# Prompting"],"id":"r4NZYpQXLAte"},{"cell_type":"code","source":["disease = \"\"\"{'DISEASE': 'if the given text contains TNBC stage I (only), \\\n","                          Unresectable stage III TNBC, \\\n","                          Metastatic disease (stage IV), and \\\n","                          Patients treated in the adjuvant settings \\\n","                          should be excluded'}\"\"\"\n","study_design = \"\"\"{'STUDY DESIGN': 'If the given text does not include Full economic evaluations, \\\n","                                    including cost-consequence analyses, cost-minimization analyses, \\\n","                                    cost-effectiveness analyses, cost-utility analyses, and cost-benefit analyses, \\\n","                                    then these should be excluded'}\"\"\"\n","outcome = \"\"\"{'OUTCOME': 'If the given text does not include Cost benefit/comparison, \\\n","                          Costs per utility/clinical outcome, ICER'}\"\"\"\n","intervention = \"\"\"{'INTERVENTION': 'if the given text contains Non-pharmacological therapies, \\\n","                                    Pharmacological interventions to manage chemotherapy side-effects should be excluded'}\"\"\"\n","exclusion_criteria = [(disease, 'DISEASE'), (study_design, 'STUDY DESIGN'), (outcome, 'OUTCOME'), (intervention, 'INTERVENTION')]"],"metadata":{"id":"tbfS2fQ0NfoI"},"id":"tbfS2fQ0NfoI","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FH3KnU3LLBF"},"outputs":[],"source":["eval_sample = 10\n","\n","llm = ChatOpenAI(\n","                model_name=\"gpt-3.5-turbo-16k\",\n","                temperature=0,\n","                max_tokens=2000,\n","                # frequency_penalty=0,\n","                # presence_penalty=0,\n","                # top_p=1.0,\n","                )\n","\n","eval = proc_data.groupby('Exclusion Code').head(eval_sample).reset_index(drop=True).copy()  # Evaluating sample selection\n","\n","for criteria, label in exclusion_criteria:\n","  print(label)\n","                          # Train sample selection\n","  train = proc_data[proc_data['Exclusion Code'].isin([label, 'Include'])].groupby('Exclusion Code').head(7).reset_index(drop=True).to_records(False).tolist()\n","\n","  schema = Object(\n","                  id=\"classification\",\n","                  description=(\n","                      f'''find the apt category of the given medical based documents; \\\n","                      And classify the documents belongs to which category by following the guidelines.;\n","                      \"guidelines\": ```{criteria}```'''\n","                  ),\n","                  attributes=[\n","                      Text(\n","                          id=\"predicted\",\n","                          description=f\"category to classify: ```{label}, Include```\",\n","                          examples = train,\n","                          )\n","                            ],\n","                  many=False,\n","                  )\n","\n","  chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n","  eval[label] = eval['Info'].apply(lambda txt : chain.run(txt)['data']['classification']['predicted'])\n","\n","eval['Actual'] = eval['Exclusion Code'].apply(lambda x: 1 if x == 'Include' else 0)\n","eval['Predicted'] = eval[['DISEASE', 'STUDY DESIGN', 'OUTCOME', 'INTERVENTION']].apply(lambda row: 1 if row.nunique()==1 else 0, axis=1)\n","\n","eval.to_csv(f'/content/drive/MyDrive/Roche/prediction {str(eval_sample)}.csv', index=False)\n"],"id":"3FH3KnU3LLBF"},{"cell_type":"markdown","source":["# Demo"],"metadata":{"id":"jtceafbKMtaA"},"id":"jtceafbKMtaA"},{"cell_type":"code","source":["eval_sample = 2\n","\n","llm = ChatOpenAI(\n","                model_name=\"gpt-3.5-turbo-16k\",\n","                temperature=0,\n","                max_tokens=2000,\n","                # frequency_penalty=0,\n","                # presence_penalty=0,\n","                # top_p=1.0,\n","                )\n","\n","eval = proc_data.groupby('Exclusion Code').head(eval_sample).reset_index(drop=True).copy()  # Evaluating sample selection\n","\n","for criteria, label in exclusion_criteria:\n","  print(label)\n","                          # Train sample selection\n","  train = proc_data[proc_data['Exclusion Code'].isin([label, 'Include'])].groupby('Exclusion Code').head(2).reset_index(drop=True).to_records(False).tolist()\n","\n","  schema = Object(\n","                  id=\"classification\",\n","                  description=(\n","                      f'''find the apt category of the given medical based documents; \\\n","                      And classify the documents belongs to which category by following the guidelines.;\n","                      \"guidelines\": ```{criteria}```'''\n","                  ),\n","                  attributes=[\n","                      Text(\n","                          id=\"predicted\",\n","                          description=f\"category to classify: ```{label}, Include```\",\n","                          examples = train,\n","                          )\n","                            ],\n","                  many=False,\n","                  )\n","\n","  chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n","  for i in eval.itertuples(index=False):\n","    print(chain.run(list(i)[0])['data'])\n","\n","  #eval[label] = eval['Info'].apply(lambda txt : chain.run(txt)['data']['classification']['predicted'])\n","\n"],"metadata":{"id":"IHQhQq8W8slL"},"id":"IHQhQq8W8slL","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L4peTM5GNyWK"},"id":"L4peTM5GNyWK","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}