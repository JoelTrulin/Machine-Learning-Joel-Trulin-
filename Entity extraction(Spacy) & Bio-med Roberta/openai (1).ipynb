{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eMg6RM2CKp0U",
   "metadata": {
    "id": "eMg6RM2CKp0U"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4599f-f331-48fa-ab0c-b2ae485fa590",
   "metadata": {
    "id": "e2d4599f-f331-48fa-ab0c-b2ae485fa590",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install kor\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f31380-87a1-4d6f-ab4d-66ff1c42a889",
   "metadata": {
    "id": "b1f31380-87a1-4d6f-ab4d-66ff1c42a889"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text\n",
    "\n",
    "\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gsU4rA-KZcDr",
   "metadata": {
    "id": "gsU4rA-KZcDr"
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kovqt9BxZ-wB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25439,
     "status": "ok",
     "timestamp": 1694065795511,
     "user": {
      "displayName": "Joel Trulin J",
      "userId": "11165460193007417230"
     },
     "user_tz": -330
    },
    "id": "Kovqt9BxZ-wB",
    "outputId": "85c21003-36a7-40cb-b278-23ce945b61cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2V__KCz2ZhsL",
   "metadata": {
    "id": "2V__KCz2ZhsL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from IPython.display import display, HTML\n",
    "# Read Dataset\n",
    "data = pd.read_excel('/content/drive/MyDrive/Roche/04. ETNBC Utils - Sent to CapeStart.xlsx', usecols=[\n",
    "                     'Title', 'Abstract', 'Exclusion Code']).dropna(axis=0, subset=['Title', 'Abstract']).fillna('Include')\n",
    "data['Info'] = data['Title'].astype(str) + data['Abstract'].astype(str)\n",
    "proc_data = data[['Info', 'Exclusion Code']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r4NZYpQXLAte",
   "metadata": {
    "id": "r4NZYpQXLAte"
   },
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tbfS2fQ0NfoI",
   "metadata": {
    "id": "tbfS2fQ0NfoI"
   },
   "outputs": [],
   "source": [
    "disease = \"\"\"{'DISEASE': 'if the given text contains TNBC stage I (only), \\\n",
    "                          Unresectable stage III TNBC, \\\n",
    "                          Metastatic disease (stage IV), and \\\n",
    "                          Patients treated in the adjuvant settings \\\n",
    "                          should be excluded'}\"\"\"\n",
    "study_design = \"\"\"{'STUDY DESIGN': 'If the given text does not include Full economic evaluations, \\\n",
    "                                    including cost-consequence analyses, cost-minimization analyses, \\\n",
    "                                    cost-effectiveness analyses, cost-utility analyses, and cost-benefit analyses, \\\n",
    "                                    then these should be excluded'}\"\"\"\n",
    "outcome = \"\"\"{'OUTCOME': 'If the given text does not include Cost benefit/comparison, \\\n",
    "                          Costs per utility/clinical outcome, ICER'}\"\"\"\n",
    "intervention = \"\"\"{'INTERVENTION': 'if the given text contains Non-pharmacological therapies, \\\n",
    "                                    Pharmacological interventions to manage chemotherapy side-effects should be excluded'}\"\"\"\n",
    "exclusion_criteria = [(disease, 'DISEASE'), (study_design, 'STUDY DESIGN'), (outcome, 'OUTCOME'), (intervention, 'INTERVENTION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3FH3KnU3LLBF",
   "metadata": {
    "id": "3FH3KnU3LLBF"
   },
   "outputs": [],
   "source": [
    "eval_sample = 10\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo-16k\",\n",
    "                temperature=0,\n",
    "                max_tokens=2000,\n",
    "                # frequency_penalty=0,\n",
    "                # presence_penalty=0,\n",
    "                # top_p=1.0,\n",
    "                )\n",
    "\n",
    "eval = proc_data.groupby('Exclusion Code').head(eval_sample).reset_index(drop=True).copy()  # Evaluating sample selection\n",
    "\n",
    "for criteria, label in exclusion_criteria:\n",
    "  print(label)\n",
    "                          # Train sample selection\n",
    "  train = proc_data[proc_data['Exclusion Code'].isin([label, 'Include'])].groupby('Exclusion Code').head(7).reset_index(drop=True).to_records(False).tolist()\n",
    "\n",
    "  schema = Object(\n",
    "                  id=\"classification\",\n",
    "                  description=(\n",
    "                      f'''find the apt category of the given medical based documents; \\\n",
    "                      And classify the documents belongs to which category by following the guidelines.;\n",
    "                      \"guidelines\": ```{criteria}```'''\n",
    "                  ),\n",
    "                  attributes=[\n",
    "                      Text(\n",
    "                          id=\"predicted\",\n",
    "                          description=f\"category to classify: ```{label}, Include```\",\n",
    "                          examples = train,\n",
    "                          )\n",
    "                            ],\n",
    "                  many=False,\n",
    "                  )\n",
    "\n",
    "  chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n",
    "  eval[label] = eval['Info'].apply(lambda txt : chain.run(txt)['data']['classification']['predicted'])\n",
    "\n",
    "eval['Actual'] = eval['Exclusion Code'].apply(lambda x: 1 if x == 'Include' else 0)\n",
    "eval['Predicted'] = eval[['DISEASE', 'STUDY DESIGN', 'OUTCOME', 'INTERVENTION']].apply(lambda row: 1 if row.nunique()==1 else 0, axis=1)\n",
    "\n",
    "eval.to_csv(f'/content/drive/MyDrive/Roche/prediction {str(eval_sample)}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jtceafbKMtaA",
   "metadata": {
    "id": "jtceafbKMtaA"
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IHQhQq8W8slL",
   "metadata": {
    "id": "IHQhQq8W8slL"
   },
   "outputs": [],
   "source": [
    "eval_sample = 2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "                model_name=\"gpt-3.5-turbo-16k\",\n",
    "                temperature=0,\n",
    "                max_tokens=2000,\n",
    "                # frequency_penalty=0,\n",
    "                # presence_penalty=0,\n",
    "                # top_p=1.0,\n",
    "                )\n",
    "\n",
    "eval = proc_data.groupby('Exclusion Code').head(eval_sample).reset_index(drop=True).copy()  # Evaluating sample selection\n",
    "\n",
    "for criteria, label in exclusion_criteria:\n",
    "  print(label)\n",
    "                          # Train sample selection\n",
    "  train = proc_data[proc_data['Exclusion Code'].isin([label, 'Include'])].groupby('Exclusion Code').head(2).reset_index(drop=True).to_records(False).tolist()\n",
    "\n",
    "  schema = Object(\n",
    "                  id=\"classification\",\n",
    "                  description=(\n",
    "                      f'''find the apt category of the given medical based documents; \\\n",
    "                      And classify the documents belongs to which category by following the guidelines.;\n",
    "                      \"guidelines\": ```{criteria}```'''\n",
    "                  ),\n",
    "                  attributes=[\n",
    "                      Text(\n",
    "                          id=\"predicted\",\n",
    "                          description=f\"category to classify: ```{label}, Include```\",\n",
    "                          examples = train,\n",
    "                          )\n",
    "                            ],\n",
    "                  many=False,\n",
    "                  )\n",
    "\n",
    "  chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n",
    "  for i in eval.itertuples(index=False):\n",
    "    print(chain.run(list(i)[0])['data'])\n",
    "\n",
    "  #eval[label] = eval['Info'].apply(lambda txt : chain.run(txt)['data']['classification']['predicted'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L4peTM5GNyWK",
   "metadata": {
    "id": "L4peTM5GNyWK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
